#!/bin/bash
#SBATCH --time=1200
#SBATCH --job-name=distill_llama
#SBATCH --ntasks=1
#SBATCH --nodes=1
#SBATCH --gres=gpu:4
#SBATCH --cpus-per-task=8
#SBATCH --account=cai_nlp
#SBATCH --mem=32G
#SBATCH --partition=gpu_top
#SBATCH --output=/cluster/home/deri/log/lmic/distill/%j_%N__ex06_venv.out
#SBATCH --error=/cluster/home/deri/log/lmic/distill/%j_%N__ex06_venv.err

cd /cluster/home/deri/hf_lmic

env_name="hf_lmic"

# load modules
module load python/3.12.4
VENV=$env_name module load uv/0.6.12
uv venv

source /scratch/venvs/$env_name/bin/activate

uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128
uv pip install git+https://github.com/huggingface/transformers.git
uv pip install -U "nvidia-modelopt[all]"
uv pip install sentencepiece bitsandbytes trl python-dotenv

export PYTHONPATH="/cluster/home/deri/hf_lmic/src:$PYTHONPATH"
export PYTHONPATH="/cluster/home/deri/hf_lmic:$PYTHONPATH"
export HF_HOME='/scratch/hf_home/'
export WANDB_DIR='/scratch/wandb/'

cd /cluster/home/deri/TensorRT-Model-Optimizer/examples/llm_distill

accelerate launch  --multi_gpu --mixed_precision  bf16 main.py --teacher_name_or_path meta-llama/Llama-3.2-1B --student_name_or_path meta-llama/Llama-3.2-1B --output_dir ./llama2-distill --logging_steps 5 --max_steps 200 --max_length 256 --per_device_train_batch_size 8 --per_device_eval_batch_size 4 --gradient_checkpointing False
